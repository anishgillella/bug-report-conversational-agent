"""
LLM chat module for bug reporting via OpenRouter API.
Pure LLM-driven conversation with minimal hardcoding.
"""
import json
from datetime import datetime
from typing import List, Dict, Any
from openai import OpenAI

from config import Config
from models import BugReport, ConversationOutput
from prompts import ConversationPrompts, ExtractionPrompts, ToolDefinitions
from data_manager import DataManager


class BugReportingBot:
    """LLM-driven bot for bug reporting. All conversation text generated by LLM."""
    
    def __init__(self, data_manager: DataManager):
        """Initialize the bot with OpenRouter client and data manager."""
        # Validate configuration
        Config.validate()
        
        self.data_manager = data_manager
        
        # Initialize OpenRouter client
        client_config = Config.get_api_client_config()
        self.client = OpenAI(**client_config)
        self.model = Config.OPENROUTER_MODEL
        
        # Conversation state
        self.messages: List[Dict[str, Any]] = []
        self.turn_count = 0
        self.max_turns = Config.MAX_CONVERSATION_TURNS
        
        # Completed bug reports
        self.completed_reports: List[BugReport] = []
        
        # Conversation trace for auditing
        self.trace: List[Dict[str, Any]] = []
    
    def _get_system_prompt(self) -> str:
        """System prompt - guides LLM to conduct natural bug reporting conversation."""
        return ConversationPrompts.get_system_prompt()
    
    def _get_tools(self) -> List[Dict[str, Any]]:
        """Define available tools for the LLM."""
        return ToolDefinitions.get_tools()
    
    def _execute_tool(self, tool_name: str, tool_input: Dict[str, Any]) -> str:
        """Execute a tool and return result as JSON string."""
        if tool_name == "verify_developer":
            identifier = tool_input.get("name", "").strip()
            developer = None
            
            # Try to parse as developer ID (number)
            if identifier.isdigit():
                dev_id = int(identifier)
                # Find by ID
                for dev in self.data_manager.developers:
                    if dev["developer_id"] == dev_id:
                        developer = dev
                        break
            
            # If not a number or not found, try as name
            if not developer:
                developer = self.data_manager.find_developer_by_name(identifier)
            
            if developer:
                return json.dumps({
                    "success": True,
                    "developer_id": developer["developer_id"],
                    "name": developer["name"]
                })
            
            # Try to find partial matches
            similar = self.data_manager.find_similar_developers(identifier)
            if similar:
                if len(similar) == 1:
                    return json.dumps({
                        "type": "partial_match_needs_confirmation",
                        "confirmation_required": True,
                        "message": f'I found a partial match for your name. Did you mean "{similar[0]["name"]}"? Please confirm with yes or no.',
                        "suggested_name": similar[0]["name"],
                        "developer_id": similar[0]["developer_id"]
                    })
                else:
                    names = [d["name"] for d in similar]
                    return json.dumps({
                        "type": "multiple_matches",
                        "message": f"I found multiple developers with similar names: {', '.join(names)}. Please clarify which one is correct.",
                        "options": names
                    })
            
            # No matches
            all_developers = self.data_manager.developers
            names = [d["name"] for d in all_developers]
            return json.dumps({
                "success": False,
                "message": f"Developer '{identifier}' not found. Valid developers are: {', '.join(names)}"
            })
        
        elif tool_name == "get_bugs_for_developer":
            developer_id = tool_input.get("developer_id")
            bugs = self.data_manager.get_bugs_for_developer(developer_id)
            return json.dumps({
                "success": True,
                "bugs": bugs
            })
        
        return json.dumps({"error": "Unknown tool"})
    
    def get_bot_response(self) -> str:
        """Get response from LLM - handles tools and returns conversation text."""
        messages_with_system = [
            {"role": "system", "content": self._get_system_prompt()}
        ] + self.messages
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages_with_system,
            tools=self._get_tools(),
            max_tokens=Config.LLM_MAX_TOKENS
        )
        
        assistant_message = response.choices[0].message
        
        # Handle tool calls
        if hasattr(assistant_message, 'tool_calls') and assistant_message.tool_calls:
            # Add assistant's tool call to messages
            self.messages.append({
                "role": "assistant",
                "content": assistant_message.content or "",
                "tool_calls": [
                    {
                        "id": tc.id,
                        "type": "function",
                        "function": {
                            "name": tc.function.name,
                            "arguments": tc.function.arguments
                        }
                    }
                    for tc in assistant_message.tool_calls
                ]
            })
            
            # Execute tools and collect results
            for tool_call in assistant_message.tool_calls:
                tool_result = self._execute_tool(
                    tool_call.function.name,
                    json.loads(tool_call.function.arguments)
                )
                
                # Add tool result to messages
                self.messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": tool_result
                })
            
            # Get follow-up response after tool execution
            follow_up_response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._get_system_prompt()}
                ] + self.messages,
                tools=self._get_tools(),
                max_tokens=Config.LLM_MAX_TOKENS
            )
            
            follow_up_message = follow_up_response.choices[0].message
            
            # Check if follow-up has ANOTHER tool call (recursive case)
            if hasattr(follow_up_message, 'tool_calls') and follow_up_message.tool_calls:
                # Another tool call! Add this message and execute the nested tools
                self.messages.append({
                    "role": "assistant",
                    "content": follow_up_message.content or "",
                    "tool_calls": [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        }
                        for tc in follow_up_message.tool_calls
                    ]
                })
                
                # Execute the nested tool calls
                for tool_call in follow_up_message.tool_calls:
                    tool_result = self._execute_tool(
                        tool_call.function.name,
                        json.loads(tool_call.function.arguments)
                    )
                    
                    # Add tool result to messages
                    self.messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": tool_result
                    })
                
                # Now recursively handle any further tool calls
                return self.get_bot_response()
            else:
                # Regular text response - add and return it
                self.messages.append({
                    "role": "assistant",
                    "content": follow_up_message.content
                })
                return follow_up_message.content or ""
        
        # No tool calls - just regular response
        self.messages.append({
            "role": "assistant",
            "content": assistant_message.content
        })
        
        return assistant_message.content or ""
    
    def _analyze_conversation_for_reports(self) -> List[BugReport]:
        """
        FINAL ANALYSIS: Analyze entire conversation and extract all completed bug reports.
        This is done ONCE at the end, after conversation is complete.
        """
        # Build full conversation text
        conv_text = ""
        for msg in self.messages:
            role = msg.get("role", "").upper()
            content = msg.get("content", "").strip()
            conv_text += f"{role}: {content}\n"
        
        # Get final analysis prompt
        analysis_prompt = ExtractionPrompts.get_final_analysis_prompt().format(
            conversation_text=conv_text
        )
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": analysis_prompt}],
                max_tokens=Config.EXTRACTION_MAX_TOKENS * 2  # More tokens for multiple reports
            )
            
            extracted_text = response.choices[0].message.content.strip()
            
            # Find and parse JSON array - handle markdown code blocks
            # Remove markdown code blocks if present
            if '```' in extracted_text:
                # Extract content between ``` markers
                parts = extracted_text.split('```')
                if len(parts) >= 2:
                    extracted_text = parts[1]  # Get content between first ``` and second ```
                    if extracted_text.startswith('json'):
                        extracted_text = extracted_text[4:]  # Remove 'json' language tag
                    extracted_text = extracted_text.strip()
            
            # Find and parse JSON array
            start = extracted_text.find('[')
            end = extracted_text.rfind(']') + 1
            
            if start >= 0 and end > start:
                json_str = extracted_text[start:end]
                parsed_list = json.loads(json_str)
                
                # Convert to BugReport objects
                reports = []
                for item in parsed_list:
                    try:
                        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        report = BugReport(
                            bug_id=item['bug_id'],
                            progress_note=f"{timestamp} - {item['progress_note']}",
                            status=item['status'],
                            solved=item['solved']
                        )
                        reports.append(report)
                    except (KeyError, ValueError) as e:
                        pass
                
                return reports
        except Exception:
            pass
        
        return []
    
    def _should_end_conversation(self) -> bool:
        """Detect if conversation should end.
        Checks if:
        1. Last user message contains "no" (to "anything else?")
        2. Reached max turns
        3. Got EOF
        """
        if not self.messages or len(self.messages) < 10:
            return False
        
        # Get last user message
        for msg in reversed(self.messages):
            if msg.get("role") == "user":
                last_user = msg.get("content", "").lower().strip()
                # Check if user said "no" to "anything else?"
                if last_user in ["no", "nope", "no thanks", "nothing else", "done"]:
                    return True
                break
        
        return False
    
    def _get_final_summary(self) -> str:
        """Generate a final summary of all completed reports using Pydantic models."""
        if not self.completed_reports:
            return "No bug reports were completed in this session."
        
        summary_lines = ["Here's the summary of your bug report(s):\n"]
        
        for i, report in enumerate(self.completed_reports, 1):
            summary_lines.append(f"**Bug Report #{i}:**")
            summary_lines.append(f"  • Bug ID: {report.bug_id}")
            summary_lines.append(f"  • Status: {report.status}")
            summary_lines.append(f"  • Solved: {'Yes' if report.solved else 'No'}")
            summary_lines.append(f"  • Work Done: {report.progress_note.split(' - ', 1)[1] if ' - ' in report.progress_note else report.progress_note}")
            summary_lines.append("")
        
        summary_lines.append("This information has been saved to the bug tracking system.")
        return "\n".join(summary_lines)
    
    def add_user_message(self, content: str) -> None:
        """Add user message to conversation history."""
        self.messages.append({"role": "user", "content": content})
    
    def run_interactive(self) -> None:
        """Run the interactive bug reporting conversation."""
        print("\n" + "="*60)
        print("BUG REPORTING CHATBOT")
        print("="*60 + "\n")
        
        # Let LLM start the conversation
        initial_response = self.get_bot_response()
        print(f"Bot: {initial_response}\n")
        self.trace.append({"type": "message", "role": "assistant", "content": initial_response})
        
        while self.turn_count < self.max_turns:
            # Get user input
            try:
                user_input = input("You: ").strip()
            except EOFError:
                # End of input stream - run final analysis before breaking
                break
            
            if user_input.lower() == "quit":
                break
            
            if not user_input:
                continue
            
            self.turn_count += 1
            self.add_user_message(user_input)
            self.trace.append({"type": "message", "role": "user", "content": user_input})
            
            # Check if user wants to end conversation BEFORE getting bot response
            # This way we detect end signals before bot generates farewell
            if self._should_end_conversation():
                break
            
            # Get next bot response (only if conversation hasn't ended)
            bot_response = self.get_bot_response()
            print(f"Bot: {bot_response}\n")
            self.trace.append({"type": "message", "role": "assistant", "content": bot_response})
        
        # After loop ends (either naturally or from break), run final analysis
        self.completed_reports = self._analyze_conversation_for_reports()
        
        # Show final summary to user
        summary = self._get_final_summary()
        print(f"Bot: {summary}\n")
        self.trace.append({"type": "message", "role": "assistant", "content": summary})
    
    def get_structured_output(self) -> ConversationOutput:
        """Generate final structured output."""
        if self.completed_reports:
            return ConversationOutput(
                success=True,
                reports=self.completed_reports
            )
        
        return ConversationOutput(
            success=False,
            reports=[]
        )
