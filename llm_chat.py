"""
LLM chat module for bug reporting via OpenRouter API.
Pure LLM-driven conversation with minimal hardcoding.
"""
import json
from datetime import datetime
from typing import Optional, List, Dict, Any
from openai import OpenAI

from config import Config
from models import BugReport, ConversationOutput, ExtractedBugInfo, ConversationEndSignal
from prompts import ConversationPrompts, ExtractionPrompts, ToolDefinitions
from data_manager import DataManager


class BugReportingBot:
    """LLM-driven bot for bug reporting. All conversation text generated by LLM."""
    
    def __init__(self, data_manager: DataManager):
        """Initialize the bot with OpenRouter client and data manager."""
        # Validate configuration
        Config.validate()
        
        self.data_manager = data_manager
        
        # Initialize OpenRouter client
        client_config = Config.get_api_client_config()
        self.client = OpenAI(**client_config)
        self.model = Config.OPENROUTER_MODEL
        
        # Conversation state
        self.messages: List[Dict[str, Any]] = []
        self.turn_count = 0
        self.max_turns = Config.MAX_CONVERSATION_TURNS
        
        # Gathered information (extracted from conversation)
        self.developer_id: Optional[int] = None
        self.selected_bug_id: Optional[int] = None
        self.progress_note: Optional[str] = None
        self.status: Optional[str] = None
        self.solved: Optional[bool] = None
        
        # Conversation trace
        self.trace: List[Dict[str, Any]] = []
        self.completed_reports: List[BugReport] = []
    
    def _get_system_prompt(self) -> str:
        """System prompt - guides LLM to conduct natural bug reporting conversation."""
        return ConversationPrompts.get_system_prompt()
    
    def _get_tools(self) -> List[Dict[str, Any]]:
        """Define available tools for the LLM."""
        return ToolDefinitions.get_tools()
    
    def _execute_tool(self, tool_name: str, tool_input: Dict[str, Any]) -> str:
        """Execute a tool and return result as JSON string."""
        if tool_name == "verify_developer":
            name = tool_input.get("name", "")
            developer = self.data_manager.find_developer_by_name(name)
            
            if developer:
                self.developer_id = developer["developer_id"]
                return json.dumps({
                    "success": True,
                    "developer_id": developer["developer_id"],
                    "name": developer["name"]
                })
            
            # Try to find partial matches
            similar = self.data_manager.find_similar_developers(name)
            if similar:
                if len(similar) == 1:
                    return json.dumps({
                        "type": "partial_match_needs_confirmation",
                        "confirmation_required": True,
                        "message": f'I found a partial match for your name. Did you mean "{similar[0]["name"]}"? Please confirm with yes or no.',
                        "suggested_name": similar[0]["name"],
                        "developer_id": similar[0]["developer_id"]
                    })
                else:
                    names = [d["name"] for d in similar]
                    return json.dumps({
                        "type": "multiple_matches",
                        "message": f"I found multiple developers with similar names: {', '.join(names)}. Please clarify which one is correct.",
                        "options": names
                    })
            
            # No matches
            all_developers = self.data_manager.developers
            names = [d["name"] for d in all_developers]
            return json.dumps({
                "success": False,
                "message": f"Developer '{name}' not found. Valid developers are: {', '.join(names)}"
            })
        
        elif tool_name == "get_bugs_for_developer":
            developer_id = tool_input.get("developer_id")
            bugs = self.data_manager.get_bugs_for_developer(developer_id)
            return json.dumps({
                "success": True,
                "bugs": bugs
            })
        
        return json.dumps({"error": "Unknown tool"})
    
    def get_bot_response(self) -> str:
        """Get response from LLM - handles tools and returns conversation text."""
        messages_with_system = [
            {"role": "system", "content": self._get_system_prompt()}
        ] + self.messages
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages_with_system,
            tools=self._get_tools(),
            max_tokens=Config.LLM_MAX_TOKENS
        )
        
        assistant_message = response.choices[0].message
        
        # Handle tool calls
        if hasattr(assistant_message, 'tool_calls') and assistant_message.tool_calls:
            # Add assistant's tool call to messages
            self.messages.append({
                "role": "assistant",
                "content": assistant_message.content or "",
                "tool_calls": [
                    {
                        "id": tc.id,
                        "type": "function",
                        "function": {
                            "name": tc.function.name,
                            "arguments": tc.function.arguments
                        }
                    }
                    for tc in assistant_message.tool_calls
                ]
            })
            
            # Execute tools and collect results
            for tool_call in assistant_message.tool_calls:
                tool_result = self._execute_tool(
                    tool_call.function.name,
                    json.loads(tool_call.function.arguments)
                )
                
                # Add tool result to messages
                self.messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": tool_result
                })
            
            # Get follow-up response after tool execution
            follow_up_response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._get_system_prompt()}
                ] + self.messages,
                tools=self._get_tools(),
                max_tokens=Config.LLM_MAX_TOKENS
            )
            
            follow_up_message = follow_up_response.choices[0].message
            self.messages.append({
                "role": "assistant",
                "content": follow_up_message.content
            })
            
            return follow_up_message.content or ""
        
        # No tool calls - just regular response
        self.messages.append({
            "role": "assistant",
            "content": assistant_message.content
        })
        
        return assistant_message.content or ""
    
    def _extract_selected_bug_id(self) -> Optional[int]:
        """Extract which bug the user selected from the conversation."""
        # Get recent messages
        recent_messages = self.messages[-6:]
        
        conv_text = ""
        for msg in recent_messages:
            role = msg.get("role", "").upper()
            content = msg.get("content", "").strip()
            conv_text += f"{role}: {content}\n"
        
        prompt = ExtractionPrompts.get_bug_id_extraction_prompt().format(conv_text=conv_text)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=50
            )
            
            extracted_text = response.choices[0].message.content.strip()
            
            # Find and parse JSON
            start = extracted_text.find('{')
            end = extracted_text.rfind('}') + 1
            
            if start >= 0 and end > start:
                json_str = extracted_text[start:end]
                parsed = json.loads(json_str)
                return parsed.get("bug_id")
        except Exception:
            pass
        
        return None
    
    def _extract_info_from_conversation(self) -> ExtractedBugInfo:
        """Extract bug report info from conversation history using Pydantic model."""
        # Only extract from the MOST RECENT part of the conversation
        recent_messages = self.messages[-10:]
        
        conv_text = ""
        for msg in recent_messages:
            role = msg.get("role", "").upper()
            content = msg.get("content", "").strip()
            conv_text += f"{role}: {content}\n"
        
        # Get extraction prompt from prompts module
        extraction_prompt = ExtractionPrompts.get_bug_info_extraction_prompt(
            self.selected_bug_id
        ).format(conv_text=conv_text)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": extraction_prompt}],
                max_tokens=Config.EXTRACTION_MAX_TOKENS
            )
            
            extracted_text = response.choices[0].message.content.strip()
            
            # Find and parse JSON
            start = extracted_text.find('{')
            end = extracted_text.rfind('}') + 1
            
            if start >= 0 and end > start:
                json_str = extracted_text[start:end]
                parsed = json.loads(json_str)
                # Use Pydantic model for validation and type conversion
                return ExtractedBugInfo(**parsed)
        except Exception:
            pass
        
        # Return empty model with all None values
        return ExtractedBugInfo()
    
    def _should_end_conversation(self) -> bool:
        """Let LLM detect if conversation should end using Pydantic model."""
        if not self.messages:
            return False
        
        # NEVER end if no reports have been completed yet
        if not self.completed_reports:
            return False
        
        # Get recent conversation
        recent = self.messages[-3:]
        recent_text = "\n".join([f"{m.get('role')}: {m.get('content', '')[:100]}" for m in recent])
        
        # Get prompt from prompts module
        end_prompt = ExtractionPrompts.get_conversation_end_prompt().format(recent_text=recent_text)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": end_prompt}],
                max_tokens=Config.END_DETECTION_MAX_TOKENS
            )
            extracted_text = response.choices[0].message.content.strip()
            
            # Find and parse JSON
            start = extracted_text.find('{')
            end = extracted_text.rfind('}') + 1
            
            if start >= 0 and end > start:
                json_str = extracted_text[start:end]
                parsed = json.loads(json_str)
                signal = ConversationEndSignal(**parsed)
                return signal.should_end
        except Exception:
            pass
        
        return False
    
    def _get_final_summary(self) -> str:
        """Generate a final summary of all completed reports using Pydantic models."""
        if not self.completed_reports:
            return "No bug reports were completed in this session."
        
        summary_lines = ["Here's the summary of your bug report(s):\n"]
        
        for i, report in enumerate(self.completed_reports, 1):
            summary_lines.append(f"**Bug Report #{i}:**")
            summary_lines.append(f"  • Bug ID: {report.bug_id}")
            summary_lines.append(f"  • Status: {report.status}")
            summary_lines.append(f"  • Solved: {'Yes' if report.solved else 'No'}")
            summary_lines.append(f"  • Work Done: {report.progress_note.split(' - ', 1)[1] if ' - ' in report.progress_note else report.progress_note}")
            summary_lines.append("")
        
        summary_lines.append("This information has been saved to the bug tracking system.")
        return "\n".join(summary_lines)
    
    def add_user_message(self, content: str) -> None:
        """Add user message to conversation history."""
        self.messages.append({"role": "user", "content": content})
    
    def run_interactive(self) -> None:
        """Run the interactive bug reporting conversation."""
        print("\n" + "="*60)
        print("BUG REPORTING CHATBOT")
        print("="*60 + "\n")
        
        # Let LLM start the conversation
        initial_response = self.get_bot_response()
        print(f"Bot: {initial_response}\n")
        self.trace.append({"type": "message", "role": "assistant", "content": initial_response})
        
        while self.turn_count < self.max_turns:
            # Get user input
            try:
                user_input = input("You: ").strip()
            except EOFError:
                # End of input stream - graceful exit
                break
            
            if user_input.lower() == "quit":
                break
            
            if not user_input:
                continue
            
            self.turn_count += 1
            self.add_user_message(user_input)
            self.trace.append({"type": "message", "role": "user", "content": user_input})
            
            # Get next bot response
            bot_response = self.get_bot_response()
            print(f"Bot: {bot_response}\n")
            self.trace.append({"type": "message", "role": "assistant", "content": bot_response})
            
            # First, try to extract the selected bug ID if not already selected
            if self.selected_bug_id is None and self.developer_id is not None:
                # Look for bug ID in recent conversation
                selected = self._extract_selected_bug_id()
                if selected:
                    self.selected_bug_id = selected
            
            # Extract information from conversation after bot response
            # Only extract if we've already selected a bug
            if self.selected_bug_id is not None:
                extracted = self._extract_info_from_conversation()
                
                # Update all fields using Pydantic model (None means not yet answered)
                if extracted.progress_note:
                    self.progress_note = extracted.progress_note
                if extracted.status:
                    self.status = extracted.status
                if extracted.solved is not None:
                    self.solved = extracted.solved
            
            # Check if we have a complete report (all 3 fields filled)
            if (self.developer_id and self.selected_bug_id and 
                self.progress_note and self.status is not None and 
                self.solved is not None):
                
                # Save to completed reports if not already there
                if self.selected_bug_id not in [r.bug_id for r in self.completed_reports]:
                    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    report = BugReport(
                        bug_id=self.selected_bug_id,
                        progress_note=f"{timestamp} - {self.progress_note}",
                        status=self.status,
                        solved=self.solved
                    )
                    self.completed_reports.append(report)
                    
                    # Reset for next bug
                    self.selected_bug_id = None
                    self.progress_note = None
                    self.status = None
                    self.solved = None
            
            # Check if user wants to end (AFTER extracting all info)
            if self._should_end_conversation():
                # Show final summary to user
                summary = self._get_final_summary()
                print(f"Bot: {summary}\n")
                self.trace.append({"type": "message", "role": "assistant", "content": summary})
                break
    
    def get_structured_output(self) -> ConversationOutput:
        """Generate final structured output."""
        if self.completed_reports:
            return ConversationOutput(
                success=True,
                report=self.completed_reports[0]
            )
        
        return ConversationOutput(
            success=False,
            report=None
        )
