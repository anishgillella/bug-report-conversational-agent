"""
LLM chat module for bug reporting via OpenRouter API.
Pure LLM-driven conversation with minimal hardcoding.
"""
import json
import os
from datetime import datetime
from typing import Optional, List, Dict, Any
from pathlib import Path
from openai import OpenAI
from pydantic import BaseModel, Field
from data_manager import DataManager


# Only essential Pydantic models
class BugReport(BaseModel):
    """Structured bug report from conversation."""
    bug_id: int = Field(..., description="Unique bug identifier")
    progress_note: str = Field(..., description="Timestamped progress entry")
    status: str = Field(..., description="Bug status (Open, In Progress, Testing, Resolved, Closed)")
    solved: bool = Field(..., description="Whether bug is solved")


class ConversationOutput(BaseModel):
    """Final structured output from conversation."""
    success: bool = Field(..., description="Whether conversation gathered all required info")
    report: Optional[BugReport] = Field(None, description="Bug report if successful")


class BugReportingBot:
    """LLM-driven bot for bug reporting. All conversation text generated by LLM."""
    
    def __init__(self, data_manager: DataManager):
        """Initialize the bot with OpenRouter client and data manager."""
        self.data_manager = data_manager
        
        # Initialize OpenRouter client
        api_key = os.getenv("OPENROUTER_API_KEY")
        model = os.getenv("OPENROUTER_MODEL")
        
        if not api_key or not model:
            raise ValueError("OPENROUTER_API_KEY and OPENROUTER_MODEL must be set in environment")
        
        self.client = OpenAI(
            api_key=api_key,
            base_url="https://openrouter.ai/api/v1"
        )
        self.model = model
        
        # Conversation state
        self.messages: List[Dict[str, Any]] = []
        self.turn_count = 0
        self.max_turns = 20
        
        # Gathered information (extracted from conversation)
        self.developer_id: Optional[int] = None
        self.selected_bug_id: Optional[int] = None
        self.progress_note: Optional[str] = None
        self.status: Optional[str] = None
        self.solved: Optional[bool] = None
        
        # Conversation trace
        self.trace: List[Dict[str, Any]] = []
        self.completed_reports: List[BugReport] = []
    
    def _get_system_prompt(self) -> str:
        """System prompt - guides LLM to conduct natural bug reporting conversation."""
        return """You are a bug reporting assistant for a development team. Your role is to have a natural conversation with developers to gather bug updates.

CONVERSATION FLOW:
1. Start by asking the developer's name
2. Use verify_developer tool to confirm the name
3. If partial match, ask for confirmation
4. Fetch their bugs using get_bugs_for_developer
5. Ask which bug they want to report on
6. Ask three specific things (one at a time):
   - What work have you done on this bug?
   - What is the current status? (Open, In Progress, Testing, Resolved, Closed)
   - Is the bug now solved/working? (Yes/No)
7. After getting all three, ask: "Is there anything else that needs updating?"
8. If user wants to update more: repeat from step 5 for another bug
9. If user says no or indicates they're done: end naturally

IMPORTANT:
- Keep conversation natural and conversational
- Ask one question at a time
- Wait for answers before proceeding
- Use tools to fetch developer and bug information
- Don't assume - always verify with user
- When asking about more updates, be natural and conversational
- When user indicates they're done, end the conversation gracefully"""
    
    def _get_tools(self) -> List[Dict[str, Any]]:
        """Define available tools for the LLM."""
        return [
            {
                "type": "function",
                "function": {
                    "name": "verify_developer",
                    "description": "Verify that a developer exists in the system by name",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "name": {
                                "type": "string",
                                "description": "The developer's name"
                            }
                        },
                        "required": ["name"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_bugs_for_developer",
                    "description": "Get all bugs assigned to a developer",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "developer_id": {
                                "type": "integer",
                                "description": "The developer's ID"
                            }
                        },
                        "required": ["developer_id"]
                    }
                }
            }
        ]
    
    def _execute_tool(self, tool_name: str, tool_input: Dict[str, Any]) -> str:
        """Execute a tool and return result as JSON string."""
        if tool_name == "verify_developer":
            name = tool_input.get("name", "")
            developer = self.data_manager.find_developer_by_name(name)
            
            if developer:
                self.developer_id = developer["developer_id"]
                return json.dumps({
                    "success": True,
                    "developer_id": developer["developer_id"],
                    "name": developer["name"]
                })
            
            # Try to find partial matches
            similar = self.data_manager.find_similar_developers(name)
            if similar:
                if len(similar) == 1:
                    return json.dumps({
                        "type": "partial_match_needs_confirmation",
                        "confirmation_required": True,
                        "message": f'I found a partial match for your name. Did you mean "{similar[0]["name"]}"? Please confirm with yes or no.',
                        "suggested_name": similar[0]["name"],
                        "developer_id": similar[0]["developer_id"]
                    })
                else:
                    names = [d["name"] for d in similar]
                    return json.dumps({
                        "type": "multiple_matches",
                        "message": f"I found multiple developers with similar names: {', '.join(names)}. Please clarify which one is correct.",
                        "options": names
                    })
            
            # No matches
            all_developers = self.data_manager.developers
            names = [d["name"] for d in all_developers]
            return json.dumps({
                "success": False,
                "message": f"Developer '{name}' not found. Valid developers are: {', '.join(names)}"
            })
        
        elif tool_name == "get_bugs_for_developer":
            developer_id = tool_input.get("developer_id")
            bugs = self.data_manager.get_bugs_for_developer(developer_id)
            return json.dumps({
                "success": True,
                "bugs": bugs
            })
        
        return json.dumps({"error": "Unknown tool"})
    
    def get_bot_response(self) -> str:
        """Get response from LLM - handles tools and returns conversation text."""
        messages_with_system = [
            {"role": "system", "content": self._get_system_prompt()}
        ] + self.messages
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages_with_system,
            tools=self._get_tools(),
            max_tokens=500
        )
        
        assistant_message = response.choices[0].message
        
        # Handle tool calls
        if hasattr(assistant_message, 'tool_calls') and assistant_message.tool_calls:
            # Add assistant's tool call to messages
            self.messages.append({
                "role": "assistant",
                "content": assistant_message.content or "",
                "tool_calls": [
                    {
                        "id": tc.id,
                        "type": "function",
                        "function": {
                            "name": tc.function.name,
                            "arguments": tc.function.arguments
                        }
                    }
                    for tc in assistant_message.tool_calls
                ]
            })
            
            # Execute tools and collect results
            for tool_call in assistant_message.tool_calls:
                tool_result = self._execute_tool(
                    tool_call.function.name,
                    json.loads(tool_call.function.arguments)
                )
                
                # Add tool result to messages
                self.messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": tool_result
                })
            
            # Get follow-up response after tool execution
            follow_up_response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._get_system_prompt()}
                ] + self.messages,
                tools=self._get_tools(),
                max_tokens=500
            )
            
            follow_up_message = follow_up_response.choices[0].message
            self.messages.append({
                "role": "assistant",
                "content": follow_up_message.content
            })
            
            return follow_up_message.content or ""
        
        # No tool calls - just regular response
        self.messages.append({
            "role": "assistant",
            "content": assistant_message.content
        })
        
        return assistant_message.content or ""
    
    def _extract_info_from_conversation(self) -> Dict[str, Any]:
        """Extract bug report info from conversation history."""
        # Use LLM to find and extract the most recent bug report from full conversation
        # This is more robust than trying to parse message order ourselves
        
        conv_text = ""
        for msg in self.messages:
            role = msg.get("role", "").upper()
            content = msg.get("content", "").strip()
            conv_text += f"{role}: {content}\n"
        
        # Simple but effective extraction prompt
        extraction_prompt = f"""From this conversation, extract the MOST RECENT user responses to these questions.
Find what the user ACTUALLY SAID (not bot descriptions):

Conversation:
{conv_text}

Return ONLY JSON:
{{
  "bug_id": <number of the bug being discussed, or null>,
  "progress_note": "<EXACTLY what user said to 'what work have you done' question>",
  "status": "<EXACTLY what status the user mentioned: Open, In Progress, Testing, Resolved, or Closed>",
  "solved": <true if user said yes/yep/fixed, false if said no/nope, null otherwise>
}}

CRITICAL:
- progress_note: User's EXACT words in response to "what work have you done"
- status: One of the 5 status values, from user's answer to "what is current status"
- solved: Boolean from user's answer to "is the bug solved/working"
- Look only at USER messages, not bot summaries or descriptions"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": extraction_prompt}],
                max_tokens=150
            )
            
            extracted_text = response.choices[0].message.content.strip()
            
            # Find and parse JSON
            start = extracted_text.find('{')
            end = extracted_text.rfind('}') + 1
            
            if start >= 0 and end > start:
                json_str = extracted_text[start:end]
                parsed = json.loads(json_str)
                return parsed
        except Exception as e:
            pass
        
        return {}
    
    def _should_end_conversation(self) -> bool:
        """Let LLM detect if conversation should end."""
        if not self.messages:
            return False
        
        # Get recent conversation
        recent = self.messages[-3:]
        recent_text = "\n".join([f"{m.get('role')}: {m.get('content', '')[:100]}" for m in recent])
        
        end_prompt = f"""Recent conversation:
{recent_text}

Based on this conversation, should we END the bug reporting session?
Answer YES only if:
- User said "no" to "anything else that needs updating?"
- User said "done", "that's it", "i'm done", "nothing more", etc.
- User explicitly indicated they have no more updates

Answer with ONLY "YES" or "NO"."""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": end_prompt}],
                max_tokens=5
            )
            answer = response.choices[0].message.content.strip().upper()
            return "YES" in answer
        except Exception:
            return False
    
    def add_user_message(self, content: str) -> None:
        """Add user message to conversation history."""
        self.messages.append({"role": "user", "content": content})
    
    def run_interactive(self) -> None:
        """Run the interactive bug reporting conversation."""
        print("\n" + "="*60)
        print("BUG REPORTING CHATBOT")
        print("="*60 + "\n")
        
        # Let LLM start the conversation
        initial_response = self.get_bot_response()
        print(f"Bot: {initial_response}\n")
        self.trace.append({"type": "message", "role": "assistant", "content": initial_response})
        
        while self.turn_count < self.max_turns:
            # Get user input
            try:
                user_input = input("You: ").strip()
            except EOFError:
                # End of input stream - graceful exit
                break
            
            if user_input.lower() == "quit":
                break
            
            if not user_input:
                continue
            
            self.turn_count += 1
            self.add_user_message(user_input)
            self.trace.append({"type": "message", "role": "user", "content": user_input})
            
            # Get next bot response
            bot_response = self.get_bot_response()
            print(f"Bot: {bot_response}\n")
            self.trace.append({"type": "message", "role": "assistant", "content": bot_response})
            
            # Extract information from conversation after bot response
            extracted = self._extract_info_from_conversation()
            
            if extracted.get("bug_id"):
                self.selected_bug_id = extracted["bug_id"]
            if extracted.get("progress_note"):
                self.progress_note = extracted["progress_note"]
            if extracted.get("status"):
                self.status = extracted["status"]
            if extracted.get("solved") is not None:
                self.solved = extracted["solved"]
            
            # Check if we have a complete report
            if (self.developer_id and self.selected_bug_id and 
                self.progress_note and self.status is not None and 
                self.solved is not None):
                
                # Save to completed reports if not already there
                if self.selected_bug_id not in [r.bug_id for r in self.completed_reports]:
                    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    report = BugReport(
                        bug_id=self.selected_bug_id,
                        progress_note=f"{timestamp} - {self.progress_note}",
                        status=self.status,
                        solved=self.solved
                    )
                    self.completed_reports.append(report)
                    
                    # Reset for next bug
                    self.selected_bug_id = None
                    self.progress_note = None
                    self.status = None
                    self.solved = None
            
            # Check if user wants to end (AFTER extracting all info)
            if self._should_end_conversation():
                break
    
    def get_structured_output(self) -> ConversationOutput:
        """Generate final structured output."""
        if self.completed_reports:
            return ConversationOutput(
                success=True,
                report=self.completed_reports[0]
            )
        
        return ConversationOutput(
            success=False,
            report=None
        )
    
    def save_trace(self, trace_path: Path) -> None:
        """Save conversation trace."""
        trace_path.parent.mkdir(parents=True, exist_ok=True)
        with open(trace_path, 'w') as f:
            json.dump(self.trace, f, indent=2)
    
    def save_output(self, output_path: Path) -> None:
        """Save structured output."""
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w') as f:
            json.dump(self.get_structured_output().model_dump(), f, indent=2)
